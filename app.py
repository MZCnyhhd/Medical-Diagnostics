import streamlit as st
import os
import sys

# è®¾ç½®é¡µé¢é…ç½®å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
st.set_page_config(
    page_title="åŒ»ç–—è¯Šæ–­ AI æ™ºèƒ½ä½“",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded",
)

try:
    import asyncio
    from dotenv import load_dotenv
    from Main import generate_diagnosis
    from Utils.config import APIKEY_ENV_PATH
    import Utils.db as db
    
    # åŠ è½½ç¯å¢ƒå˜é‡ (å¼ºåˆ¶è¦†ç›–ï¼Œç¡®ä¿è¯»å–æœ€æ–°é…ç½®)
    load_dotenv(dotenv_path=APIKEY_ENV_PATH, override=True)
    
except Exception as e:
    st.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥ï¼Œå‘ç”Ÿä¸¥é‡é”™è¯¯ï¼š\n{e}")
    st.stop()

# è‡ªå®šä¹‰ CSS
st.markdown("""
<style>
    .reportview-container {
        background: #f0f2f6
    }
    .main-header {
        font-size: 2.5rem;
        color: #0e1117;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #262730;
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
    .stTextArea textarea {
        font-size: 1rem;
    }
    /* å¡ç‰‡æ ·å¼ */
    .specialist-card {
        background-color: #ffffff;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin-bottom: 1rem;
        border-left: 5px solid #4CAF50;
    }
    .specialist-title {
        font-weight: bold;
        font-size: 1.2rem;
        margin-bottom: 0.5rem;
        color: #333;
    }
</style>
""", unsafe_allow_html=True)

def main():
    # åˆå§‹åŒ–æ•°æ®åº“
    import Utils.db as db
    db.init_db()

    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "diagnosis_result" not in st.session_state:
        st.session_state.diagnosis_result = None

    st.markdown('<h1 class="main-header">ğŸ¥ åŒ»ç–—è¯Šæ–­ AI æ™ºèƒ½ä½“</h1>', unsafe_allow_html=True)
    
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        
        # --- æ¨¡å‹åˆ‡æ¢åŠŸèƒ½ ---
        model_options = {
            "Local (DeepSeek-R1-Distill)": "local",
            "Qwen (é€šä¹‰åƒé—®)": "qwen",
            "OpenAI (GPT-3.5/4)": "openai",
            "Gemini (Google)": "gemini"
        }
        
        # è·å–å½“å‰ç¯å¢ƒå˜é‡ä¸­çš„é»˜è®¤å€¼
        current_provider = os.getenv("LLM_PROVIDER", "local")
        # åå‘æŸ¥æ‰¾å¯¹åº”çš„ index
        default_index = 0
        for idx, (name, key) in enumerate(model_options.items()):
            if key == current_provider:
                default_index = idx
                break
        
        selected_model_name = st.selectbox(
            "é€‰æ‹© AI æ¨¡å‹",
            options=list(model_options.keys()),
            index=default_index,
            help="é€‰æ‹©ç”¨äºè¯Šæ–­å’Œå¯¹è¯çš„åº•å±‚å¤§æ¨¡å‹"
        )
        
        # æ›´æ–°ç¯å¢ƒå˜é‡
        selected_provider = model_options[selected_model_name]
        os.environ["LLM_PROVIDER"] = selected_provider
        if "llm_provider" not in st.session_state or st.session_state["llm_provider"] != selected_provider:
            st.session_state["llm_provider"] = selected_provider

        st.divider()

        st.header("é…ç½®ä¸è¯´æ˜")
        st.info(
            """
            **å·¥ä½œåŸç†ï¼š**
            ç³»ç»Ÿå°†åŒ»ç–—æŠ¥å‘Šåˆ†å‘ç»™å¤šä¸ªä¸“ç§‘ AI æ™ºèƒ½ä½“ï¼ˆå¿ƒè„ç§‘ã€å¿ƒç†ç§‘ã€è‚ºç§‘ç­‰ï¼‰å¹¶è¡Œåˆ†æï¼Œ
            æœ€åç”±å¤šå­¦ç§‘å›¢é˜Ÿæ•´åˆæ„è§ï¼Œç»™å‡ºç»¼åˆè¯Šæ–­å»ºè®®ã€‚
            """
        )
        
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            st.warning("æœªæ£€æµ‹åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ã€‚")
            user_api_key = st.text_input("è¯·è¾“å…¥ DashScope API Key:", type="password")
            if user_api_key:
                os.environ["DASHSCOPE_API_KEY"] = user_api_key
        else:
            st.success("DashScope API Key å·²é…ç½®")
            
        st.divider()
        if st.button("ğŸ”„ æ›´æ–°çŸ¥è¯†åº“", help="å°† KnowledgeBase ç›®å½•ä¸‹çš„æ–‡æ¡£é‡æ–°å†™å…¥å‘é‡åº“"):
            with st.spinner("æ­£åœ¨æ›´æ–°çŸ¥è¯†åº“..."):
                from ingest_knowledge import ingest_docs
                status = ingest_docs()
                if "å¤±è´¥" in status:
                    st.error(status)
                else:
                    st.success(status)

        st.divider()
        st.markdown("### ğŸ“œ å†å²è¯Šæ–­è®°å½•")
        history = db.get_history()
        if history:
            selected_history = st.selectbox(
                "æŸ¥çœ‹è¿‡å¾€ç—…ä¾‹",
                options=history,
                format_func=lambda x: f"{x['timestamp']} (ID: {x['id']})"
            )
            if selected_history:
                with st.expander("æŸ¥çœ‹è¯¦æƒ…", expanded=False):
                    st.markdown("**åŸå§‹æŠ¥å‘Š**:")
                    st.text(selected_history['report_content'][:100] + "...")
                    st.markdown("**è¯Šæ–­ç»“æœ**:")
                    st.markdown(selected_history['diagnosis_result'])
        else:
            st.info("æš‚æ— å†å²è®°å½•")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.markdown('<h2 class="sub-header">ğŸ“„ è¾“å…¥åŒ»ç–—æŠ¥å‘Š</h2>', unsafe_allow_html=True)
        
        input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["ç›´æ¥ç²˜è´´æ–‡æœ¬", "ä¸Šä¼  TXT æ–‡ä»¶", "é€‰æ‹©ç¤ºä¾‹æŠ¥å‘Š"])
        
        medical_report = ""
        
        if input_method == "ç›´æ¥ç²˜è´´æ–‡æœ¬":
            medical_report = st.text_area("åœ¨æ­¤å¤„ç²˜è´´åŒ»ç–—æŠ¥å‘Šå†…å®¹...", height=400)
        elif input_method == "ä¸Šä¼  TXT æ–‡ä»¶":
            uploaded_file = st.file_uploader("ä¸Šä¼ åŒ»ç–—æŠ¥å‘Š (.txt)", type=["txt"])
            if uploaded_file is not None:
                medical_report = uploaded_file.read().decode("utf-8")
                st.text_area("æ–‡ä»¶å†…å®¹é¢„è§ˆ", value=medical_report, height=400, disabled=True)
        elif input_method == "é€‰æ‹©ç¤ºä¾‹æŠ¥å‘Š":
            example_dir = os.path.join("Medical Reports", "Examples")
            if os.path.exists(example_dir):
                example_files = [f for f in os.listdir(example_dir) if f.endswith(".txt")]
                if example_files:
                    selected_example = st.selectbox("è¯·é€‰æ‹©ä¸€ä¸ªç¤ºä¾‹æŠ¥å‘Š", example_files)
                    if selected_example:
                        with open(os.path.join(example_dir, selected_example), "r", encoding="utf-8") as f:
                            medical_report = f.read()
                        st.text_area("ç¤ºä¾‹æŠ¥å‘Šå†…å®¹", value=medical_report, height=400)
                else:
                    st.warning("æœªæ‰¾åˆ°ç¤ºä¾‹æŠ¥å‘Šæ–‡ä»¶ã€‚")
            else:
                st.warning("ç¤ºä¾‹æŠ¥å‘Šç›®å½•ä¸å­˜åœ¨ã€‚")

        start_btn = st.button("ğŸš€ å¼€å§‹å¤šå­¦ç§‘ä¼šè¯Š", type="primary", use_container_width=True)

    # å®šä¹‰èŠå¤©åŒºåŸŸå®¹å™¨ï¼ˆæ”¾åœ¨åº•éƒ¨ï¼Œä½†æå‰å®šä¹‰ä»¥ä¾¿å¼•ç”¨ï¼‰
    st.divider()
    st.markdown('<h2 class="sub-header">ğŸ’¬ ä¸“å®¶å’¨è¯¢</h2>', unsafe_allow_html=True)
    chat_container = st.container()

    with col2:
        st.markdown('<h2 class="sub-header">ğŸ©º è¯Šæ–­è¿‡ç¨‹</h2>', unsafe_allow_html=True)
        
        # å ä½ç¬¦ï¼šç”¨äºæ˜¾ç¤ºå„ä¸“ç§‘åŒ»ç”Ÿçš„åˆ†æè¿‡ç¨‹
        specialist_placeholder = st.empty()
        
        if start_btn and medical_report:
             # æ¸…ç©ºä¹‹å‰çš„ä¼šè¯å’Œç»“æœ
            st.session_state.messages = []
            st.session_state.diagnosis_result = None

            if not os.getenv("DASHSCOPE_API_KEY") and not os.getenv("OPENAI_API_KEY") and not os.getenv("GOOGLE_API_KEY"):
                st.error("è¯·å…ˆé…ç½® API Keyï¼")
            else:
                async def run_async_diagnosis():
                    gen = generate_diagnosis(medical_report)
                    try:
                        async for agent_name, response in gen:
                            if agent_name == "Final Diagnosis":
                                st.success("ä¼šè¯Šå®Œæˆï¼")
                                
                                # --- ä¿®å¤ï¼šåŒé‡è¾“å‡ºé—®é¢˜ ---
                                # ä¸å†åœ¨ col2 ä¸­æ˜¾ç¤ºæœ€ç»ˆç»“æœï¼Œè€Œæ˜¯ç›´æ¥æµå¼è¾“å‡ºåˆ°åº•éƒ¨çš„ chat_container
                                
                                full_diagnosis = response
                                
                                # åœ¨èŠå¤©åŒºåŸŸæ˜¾ç¤ºæœ€ç»ˆè¯Šæ–­
                                with chat_container:
                                    with st.chat_message("assistant"):
                                        st.markdown("### ğŸ“‹ å¤šå­¦ç§‘å›¢é˜Ÿç»¼åˆè¯Šæ–­")
                                        message_placeholder = st.empty()
                                        
                                        # æ¨¡æ‹Ÿæµå¼æ‰“å­—æœºæ•ˆæœ
                                        displayed_text = ""
                                        chunk_size = 10
                                        for i in range(0, len(full_diagnosis), chunk_size):
                                            chunk = full_diagnosis[i:i+chunk_size]
                                            displayed_text += chunk
                                            message_placeholder.markdown(displayed_text + "â–Œ")
                                            await asyncio.sleep(0.02)
                                        message_placeholder.markdown(displayed_text)

                                # ä¿å­˜ç»“æœåˆ° Session State
                                st.session_state.diagnosis_result = full_diagnosis
                                st.session_state.messages.append({"role": "assistant", "content": f"### ğŸ“‹ å¤šå­¦ç§‘å›¢é˜Ÿç»¼åˆè¯Šæ–­\n\n{full_diagnosis}"})
                                
                                # --- æ–°å¢ï¼šæ•°æ®æŒä¹…åŒ– ---
                                db.save_consultation(medical_report, full_diagnosis)
                                
                            else:
                                # æ˜¾ç¤ºä¸“ç§‘åŒ»ç”Ÿçš„åˆ†æè¿‡ç¨‹ï¼ˆä¿æŒåœ¨ col2ï¼‰
                                with specialist_placeholder.container():
                                    st.markdown(f"""
                                    <div class="specialist-card">
                                        <div class="specialist-header">{agent_name} æ­£åœ¨åˆ†æ...</div>
                                        <div class="specialist-content">{response}</div>
                                    </div>
                                    """, unsafe_allow_html=True)
                                    await asyncio.sleep(0.5)

                    except Exception as e:
                        st.error(f"å‘ç”Ÿé”™è¯¯: {e}")

                asyncio.run(run_async_diagnosis())

    # ---------------------------------------------------------
    # èŠå¤©é—®ç­”åŒºåŸŸå†…å®¹æ¸²æŸ“
    # ---------------------------------------------------------
    # å¦‚æœåˆšç‚¹å‡»äº†å¼€å§‹æŒ‰é’®ï¼Œè¯´æ˜ä¸Šé¢å·²ç»æµå¼è¾“å‡ºäº†è¯Šæ–­ç»“æœï¼Œè¿™é‡Œå°±ä¸éœ€è¦å†æ¸²æŸ“å†å²è®°å½•äº†ï¼ˆå¦åˆ™ä¼šé‡å¤ï¼‰
    if not start_btn:
        with chat_container:
            # æ˜¾ç¤ºèŠå¤©è®°å½•
            for message in st.session_state.messages:
                if message["role"] != "system":
                     with st.chat_message(message["role"]):
                        st.markdown(message["content"])

    if prompt := st.chat_input("å¯¹è¯Šæ–­ç»“æœæœ‰ç–‘é—®ï¼Ÿè¯·åœ¨æ­¤æé—®..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"):
                st.markdown(prompt)

        # ç”Ÿæˆå›å¤
        if st.session_state.diagnosis_result:
            # é‡æ–°æ„å»º prompt
            context = f"åŸºäºä»¥ä¸‹è¯Šæ–­ç»“æœï¼š\n{st.session_state.diagnosis_result}\n\nç”¨æˆ·é—®é¢˜ï¼š{prompt}"
            
            # è·å–æ¨¡å‹
            from Utils.llm_factory import get_chat_model
            # ä½¿ç”¨é»˜è®¤é…ç½®çš„æ¨¡å‹ (é€šå¸¸æ˜¯ local æˆ– qwen)
            chat_model = get_chat_model()
            
            with chat_container:
                with st.chat_message("assistant"):
                    response_placeholder = st.empty()
                    full_response = ""
                    try:
                        # ä½¿ç”¨ stream å®ç°æµå¼è¾“å‡º
                        for chunk in chat_model.stream(context):
                            content = getattr(chunk, "content", str(chunk))
                            full_response += content
                            # å®æ—¶æ˜¾ç¤ºï¼ˆå¸¦å…‰æ ‡ï¼‰
                            response_placeholder.markdown(full_response + "â–Œ")
                        
                        # ç”Ÿæˆå®Œæˆåï¼Œè¿›è¡Œåå¤„ç†ï¼ˆæŠ˜å æ€è€ƒè¿‡ç¨‹ã€æ¸…ç† tokenï¼‰
                        
                        # --- ä¼˜åŒ–è¾“å‡ºæ˜¾ç¤º ---
                        import re
                        # 1. æå–æ€è€ƒè¿‡ç¨‹
                        thought_content = None
                        
                        # å°è¯•åŒ¹é…æ ‡å‡†çš„ <think>...</think>
                        think_match = re.search(r'<think>(.*?)</think>', full_response, re.DOTALL)
                        if think_match:
                            thought_content = think_match.group(1).strip()
                            full_response = full_response.replace(think_match.group(0), '').strip()
                        else:
                            # å¤„ç†åªæœ‰ </think> çš„æƒ…å†µ
                            end_think_match = re.search(r'(.*?)</think>', full_response, re.DOTALL)
                            if end_think_match:
                                thought_content = end_think_match.group(1).strip()
                                full_response = full_response.replace(end_think_match.group(0), '').strip()

                        if thought_content:
                            with st.expander("ğŸ’­ æ€è€ƒè¿‡ç¨‹"):
                                st.markdown(thought_content)
                        
                        # 2. æ¸…ç†å¯èƒ½æ®‹ç•™çš„ç‰¹æ®Š token
                        full_response = re.sub(r'<\|.*?\|>', '', full_response).strip()

                        # æ˜¾ç¤ºæœ€ç»ˆå¤„ç†åçš„ç»“æœï¼ˆä¸å¸¦å…‰æ ‡ï¼‰
                        response_placeholder.markdown(full_response)
                        
                        # --- æ–°å¢ï¼šå¯¼å‡ºåŠŸèƒ½ ---
                        st.divider()
                        col_pdf, col_docx = st.columns(2)
                        from Utils.export_utils import generate_pdf, generate_docx
                        
                        with col_pdf:
                            pdf_file = generate_pdf(full_response)
                            st.download_button(
                                label="ğŸ“„ ä¸‹è½½ PDF æŠ¥å‘Š",
                                data=pdf_file,
                                file_name="diagnosis_report.pdf",
                                mime="application/pdf"
                            )
                            
                        with col_docx:
                            docx_file = generate_docx(full_response)
                            st.download_button(
                                label="ğŸ“ ä¸‹è½½ Word æŠ¥å‘Š",
                                data=docx_file,
                                file_name="diagnosis_report.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )

                    except Exception as e:
                        st.error(f"å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            
            st.session_state.messages.append({"role": "assistant", "content": full_response})
        else:
            st.warning("è¯·å…ˆå®Œæˆè¯Šæ–­å†æé—®ã€‚")

if __name__ == "__main__":
    main()
